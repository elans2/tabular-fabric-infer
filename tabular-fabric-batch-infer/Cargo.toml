[package]
name = "tabular-fabric-batch-infer"
version = "0.1.0"
edition = "2021"

[lib]
name ="tabular_fabric_batch_infer"
path = "src/lib.rs"
test = false
bench = false

[dependencies]

tokio = { workspace = true }
arrow = { workspace = true }
thiserror = { version = "1.0.50" }
anyhow = { workspace = true }
itertools = { workspace = true}
structmap = { workspace = true }
structmap-derive = { workspace = true }
serde_json = { workspace = true }
tracing = { workspace = true }
tracing-subscriber = { workspace = true }

#candle-core = {  git = "https://github.com/huggingface/candle.git", branch = "main", features = ["default"] }
#candle-transformers = {  git = "https://github.com/huggingface/candle.git", branch = "main", features = ["default"] }
#candle-nn = {  git = "https://github.com/huggingface/candle.git", branch = "main", features = ["default"] }

candle-core = {  version = "0.4.1", features = ["default"] }
candle-transformers = {  version = "0.4.1", features = ["default"] }
candle-nn = {  version = "0.4.1", features = ["default"] }
tokenizers = { version = "0.13.3" }

llama_cpp_rs = { path = "../rust-llama.cpp/"}
log = "0.4.20"


[features]
cuda = ["candle-core/cuda", "candle-transformers/cuda", "candle-nn/cuda"]
